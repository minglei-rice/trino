<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!--
       Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<!-- Put site-specific property overrides in this file. -->
<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/mnt/storage00/datum/namenode01</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>
      /mnt/storage01/datum/datanode,
      /mnt/storage02/datum/datanode,
      /mnt/storage03/datum/datanode,
      /mnt/storage04/datum/datanode,
      /mnt/storage05/datum/datanode,
      /mnt/storage06/datum/datanode,
      /mnt/storage07/datum/datanode,
      /mnt/storage08/datum/datanode,
      /mnt/storage09/datum/datanode,
      /mnt/storage10/datum/datanode,
      /mnt/storage11/datum/datanode,
      /mnt/storage12/datum/datanode,
      /mnt/storage13/datum/datanode,
      /mnt/storage14/datum/datanode
    </value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/mnt/storage00/datum/journalnode</value>
  </property>
  <property>
    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
   <name>ipc.server.read.threadpool.size</name>
   <value>5</value>
  </property>
  <property>
   <name>ipc.server.read.connection-queue.size</name>
   <value>500</value>
  </property>
  <property>
   <name>ipc.server.handler.queue.size</name>
   <value>200</value>
  </property>
    <property>
        <name>dfs.nameservices</name>
        <value>jssz-bigdata-ns1,jssz-bigdata-ns2,jssz-bigdata-ns3,jssz-bigdata-ns4,jssz-bigdata-proxy-ns1,jssz-bigdata-proxy-ns2</value>
    </property>
    <!-- jssz-bigdata-ns1 start -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-ns1</name>
        <value>nn-0,nn-1</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns1.nn-0</name>
        <value>10.69.8.34:9000</value>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>1000</value>
    </property>
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>1000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns1.nn-0</name>
        <value>10.69.8.34:50070</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns1.nn-1</name>
        <value>10.69.1.30:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns1.nn-1</name>
        <value>10.69.1.30:50070</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns1.nn-0</name>
        <value>10.69.8.34:9030</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns1.nn-1</name>
        <value>10.69.1.30:9030</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns1.nn-0</name>
        <value>10.69.8.34:9010</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns1.nn-1</name>
        <value>10.69.1.30:9010</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-ns1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- jssz-bigdata-ns2 namespace -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-ns2</name>
        <value>nn-0,nn-1</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns2.nn-0</name>
        <value>10.69.1.31:9000</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns2.nn-0</name>
        <value>10.69.1.31:9010</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns2.nn-0</name>
        <value>10.69.1.31:9030</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns2.nn-0</name>
        <value>10.69.1.31:50070</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns2.nn-1</name>
        <value>10.69.1.32:9000</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns2.nn-1</name>
        <value>10.69.1.32:9010</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns2.nn-1</name>
        <value>10.69.1.32:9030</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns2.nn-1</name>
        <value>10.69.1.32:50070</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-ns2</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <!-- jssz-bigdata-ns3 start -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-ns3</name>
        <value>nn-0,nn-1</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns3.nn-0</name>
        <value>jssz-bigdata-namenode-19.host.bilibili.co:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns3.nn-0</name>
        <value>jssz-bigdata-namenode-19.host.bilibili.co:50070</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns3.nn-1</name>
        <value>jssz-bigdata-namenode-21.host.bilibili.co:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns3.nn-1</name>
        <value>jssz-bigdata-namenode-21.host.bilibili.co:50070</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns3.nn-0</name>
        <value>jssz-bigdata-namenode-19.host.bilibili.co:9030</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns3.nn-1</name>
        <value>jssz-bigdata-namenode-21.host.bilibili.co:9030</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns3.nn-0</name>
        <value>jssz-bigdata-namenode-19.host.bilibili.co:9010</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns3.nn-1</name>
        <value>jssz-bigdata-namenode-21.host.bilibili.co:9010</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-ns3</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- jssz-bigdata-ns3 end -->

    <!-- jssz-bigdata-ns4 start -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-ns4</name>
        <value>nn-0,nn-1</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns4.nn-0</name>
        <value>jssz-bigdata-namenode-20.host.bilibili.co:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns4.nn-0</name>
        <value>jssz-bigdata-namenode-20.host.bilibili.co:50070</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-ns4.nn-1</name>
        <value>jssz-bigdata-namenode-22.host.bilibili.co:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.jssz-bigdata-ns4.nn-1</name>
        <value>jssz-bigdata-namenode-22.host.bilibili.co:50070</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns4.nn-0</name>
        <value>jssz-bigdata-namenode-20.host.bilibili.co:9030</value>
    </property>
    <property>
        <name>dfs.namenode.lifeline.rpc-address.jssz-bigdata-ns4.nn-1</name>
        <value>jssz-bigdata-namenode-22.host.bilibili.co:9030</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns4.nn-0</name>
        <value>jssz-bigdata-namenode-20.host.bilibili.co:9010</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.jssz-bigdata-ns4.nn-1</name>
        <value>jssz-bigdata-namenode-22.host.bilibili.co:9010</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-ns4</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- jssz-bigdata-ns4 end -->

    <!-- jssz-bigdata-proxy-ns1 start -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-proxy-ns1</name>
        <value>nn-0,nn-1,nn-2</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns1.nn-0</name>
        <value>nnproxy-01.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns1.nn-1</name>
        <value>nnproxy-02.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns1.nn-2</name>
        <value>nnproxy-03.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-proxy-ns1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- jssz-bigdata-proxy-ns1 end -->

    <!-- jssz-bigdata-proxy-ns2 start -->
    <property>
        <name>dfs.ha.namenodes.jssz-bigdata-proxy-ns2</name>
        <value>nn-0,nn-1,nn-2</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns2.nn-0</name>
        <value>nnproxy-07.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns2.nn-1</name>
        <value>nnproxy-08.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.jssz-bigdata-proxy-ns2.nn-2</name>
        <value>nnproxy-09.bilibili.co:56310</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.jssz-bigdata-proxy-ns2</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- jssz-bigdata-proxy-ns2 end -->

  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://10.69.8.34:8485;10.69.1.30:8485;10.69.1.31:8485/jssz-bigdata-ns1</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hdfs/.ssh/id_rsa</value>
  </property>
  <!-- ha end -->
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/etc/hadoop/excludes</value>
  </property>
  <!-- balance configuration-->
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>10485760</value>
    <description>Specifies the maximum bandwidth that each datanode can utilize for the balancing purpose in term of the number of bytes per second.</description>
  </property>
  <property>
    <name>dfs.datanode.balance.max.concurrent.moves</name>
    <value>100</value>
  </property>
  <property>
    <name>dfs.balancer.moverThreads</name>
    <value>3000</value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>8192</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>500</value>
  </property>
  <property>
   <name>dfs.namenode.handler.count</name>
   <value>1000</value>
  </property>
  <property>
   <name>dfs.datanode.handler.count</name>
   <value>1000</value>
   </property>
   <property>
      <name>dfs.datanode.socket.write.timeout</name>
      <value>3000000</value>
   </property>
   <property>
      <name>dfs.client.socket-timeout</name>
      <value>120000</value>
   </property>
    <property>
        <name>dfs.client.failover.max.attempts</name>
        <value>30</value>
    </property>
    <property>
        <name>dfs.client.failover.sleep.max.millis</name>
        <value>35000</value>
    </property>
    <property>
        <name>dfs.client.retry.max.attempts</name>
        <value>30</value>
    </property>
    <property>
        <name>dfs.client.proxis.shuffle.enabled</name>
        <value>true</value>
    </property>
    <property>
      <name>dfs.blocksize</name>
      <value>536870912</value>
   </property>
    <property>
        <name>dfs.client.block.write.locateFollowingBlock.retries</name>
        <value>10</value>
    </property>
    <property>
        <name>dfs.client.retry.interval-ms.get-last-block-length</name>
        <value>6000</value>
    </property>
    <property>
        <name>dfs.client.write.max-packets-in-flight</name>
        <value>200</value>
    </property>
    <property>
        <name>ipc.client.connection.maxidletime</name>
        <value>5000</value>
    </property>
    <property>
        <name>dfs.client.socket.send.buffer.size</name>
        <value>0</value>
    </property>
    <property>
        <name>dfs.client.read.prefetch.size</name>
        <value>20</value>
    </property>
  <!--  datanode configuration  -->
  <property>
    <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
    <value>ALWAYS</value>
  </property>
  <property>
    <name>dfs.client.block.write.replace-datanode-on-failure.best-effort</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>hadoop</value>
  </property>
  <property>
    <name>dfs.permissions.supergroup</name>
    <value>hadoop</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>false</value>
  </property>
    <property>
    <name>dfs.domain.socket.path</name>
    <value>/run/hadoop/dfs.socket</value>
  </property>
  <property>
    <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
    <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy</value>
  </property>
<property>
    <name>dfs.datanode.du.reserved</name>
    <value>150000000000</value>
</property>
<property>
    <name>fs.du.interval</name>
    <value>1800000</value>
</property>
  <property>
    <name>dfs.datanode.cached-replica.check.interval.ms</name>
    <value>600000</value>
    <discription>datanode replica cache expiration time</discription>
  </property>
  <property>
    <name>dfs.datanode.cached-dfsused.check.interval.ms</name>
    <value>86400000</value>
    <discription>datanode dfsused cache expiration time</discription>
  </property>
  <property>
    <name>dfs.blockreport.initialDelay</name>
    <value>300</value>
    <discription>datanode bloack report delay time in s</discription>
  </property>
  <property>
    <name>dfs.datanode.peer.stats.enabled</name>
    <value>true</value>
    <discription>是否开启datanode慢节点检查</discription>
  </property>
  <property>
    <name>dfs.datanode.slow.peers.report.interval</name>
    <value>300000</value>
    <discription>datanode上报慢节点report的时间间隔</discription>
  </property>
  <property>
    <name>dfs.metrics.rolling.average.num.windows</name>
    <value>15</value>
    <discription>datanode统计pactet包处理时间的时间窗数量</discription>
  </property>
  <property>
    <name>dfs.metrics.low.threshold.ms</name>
    <value>1</value>
    <discription>datanode定义为慢节点的阈值(datanode处理packet的评价时间)</discription>
  </property>
  <property>
    <name>dfs.metrics.min.outlier.detection.peers</name>
    <value>5</value>
    <discription>datanode统计慢节点时最少统计的批次</discription>
  </property>
  <property>
    <name>dfs.client.replace.datanode.threshold.ms</name>
    <value>5000</value>
  </property>
    <property>
        <name>dfs.client.fast.switch.read.cwnd.rate.threshold.bytes.per.millis</name>
        <value>2237</value>
    </property>
    <property>
        <name>dfs.client.fast.switch.read.cwnd.time.millis</name>
        <value>1000</value>
    </property>
    <property>
        <name>dfs.client.fast.switch.socket-read-timeout</name>
        <value>4000</value>
    </property>
    <property>
        <name>dfs.client.fast.switch.max-socket-read-timeout</name>
        <value>30000</value>
    </property>

    <property>
        <name>dfs.client.fast.failover.write.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.client.fast.failover.write.ms</name>
        <value>5000</value>
    </property>
    <property>
        <name>dfs.client.replace.datanode.threshold.ms</name>
        <value>2000</value>
    </property>

  <!-- security config -->
  <property>
    <name>dfs.namenode.kerberos.principal</name>
    <value>nn/_HOST@BILIBILI.CO</value>
  </property>
  <property>
    <name>dfs.datanode.kerberos.principal</name>
    <value>dn/_HOST@BILIBILI.CO</value>
  </property>

  <!-- alluxio config -->
  <property>
    <name>alluxio.user.rpc.retry.base.sleep</name>
    <value>50ms</value>
  </property>
  <property>
    <name>alluxio.user.rpc.retry.max.duration</name>
    <value>5s</value>
  </property>
  <property>
    <name>alluxio.user.rpc.retry.max.sleep</name>
    <value>2s</value>
  </property>
  <property>
    <name>iceberg.alluxio.metadata.cache.enabled</name>
    <value>{ALLUXIO_CACHE}</value>
  </property>
  <property>
    <name>iceberg.alluxio.index.cache.enabled</name>
    <value>{ALLUXIO_CACHE}</value>
  </property>
</configuration>

